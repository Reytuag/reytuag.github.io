<!doctype html>
<meta charset="utf-8">
<script src="template.v1.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js" integrity="sha384-YNHdsYkH6gMx9y3mRkmcJ2mFUjTd0qNQQvY9VYZgQd7DcN7env35GzlmFaZ23JGp" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
<script type="text/front-matter">
  title: "Learning Sensorimotor Capabilities in Cellular Automata"
  description: "Description of the post"
  authors:
  - Gautier Hamon: https://reytuag.github.io/
  affiliations:
  - affiliation:
</script>



<style>
#showText {opacity:0.75; background-color:#668; color:#eef; font:0.7em Courier New; }
</style>

<dt-article  >
  <h1>Learning Sensorimotor Capabilities in Cellular Automata</h1>
  <h2> Learning robust self-organizing creatures  </h2>

  <video id="robust" width="95%"  autoplay loop muted="" class="l-middle-outset videoShow">
                <source src="demo.mp4" type="video/mp4">
              </video>
  <dt-byline></dt-byline>

  <canvas id="glCanvas" width="640" height="360" class='l-body'></canvas>
  <!--shadertoy at mac 840x472, at win 640x360-->
  <div id="showText" onclick="this.style.display='none';">initializing...</div>
  <p class="l-gutter" style="font-size: 12px;color:#A0A0A0;"> Radius 0.5 is good to spawn creatures<br> Some death in corners but always with 2 creatures while creature has only been trained alone. </p>
  <p> press p to pause and enter to clear </p>
  <div class='l-body'>
    <input type="range" min="0.1" max="1"  step="0.1" value="0.5" class="slider" id="rangeRadiusWall" >
    <p> Radius: <span id="valueRadiusWall"></span></p>
    <input type="range" min="6" max="20"  step="0.1" value="8.5" class="slider" id="rangeRadius" style="display:none">
    <p style="display:none"> Radius of kernels (size of creature): <span id="valueRadius"></span></p>
  </div>
  <div class="radio-toolbar" id="optionDiv">
    <input type="radio" id="radioErase"  name='option'  value="erase">
    <label for="radioErase">Eraser</label>

    <input type="radio" id="radioCircle"  name='option'  value="circle">
    <label for="radioCircle">Dot</label>

    <input type="radio" id="radioCreature" name='option'  value="creature" checked>
    <label for="radioCreature">Place Creature</label>
</div>

  <script type="text/javascript" src="utils.js"></script>
  <script type="text/javascript" src="gl.js"></script>




  <p>Spatially localized patterns in cellular automata have shown a lot of interesting behavior that led to new understanding of self-organizing system. While the notion of environment is a keypoint in Maturana and Varela biology of cognition, studies on cellular automata rarely introduced a well defined environment in their system. In this paper, we propose to add walls in a cellular automata to study how we can learn a self-organizing creature capable of reacting to the perturbations induced by the environment, ie robust creatures with sensorimotor capabilities. We provide a method based on curriculum learning able to learn the CA rule leading to such creature. The creature obtained,using only local update rules, are able to regenerate and preserve their individuality and structure while dealing with the obstacles in their way..</p>



  <!--
  <d-contents>
  <nav class="l-gutter text figcaption">
    <h4>Contents</h4>
    <h6><a href="#introduction">Introduction</a></h6>
    <h6><a href="#system">the system</a></h6>
    <h6><a href="#movingCrea">Learning Moving Creature in Lenia</a></h6>
    <h6><a href="#robustCrea">Learning robust creatures with sensorimotor capabilities</a></h6>
    <h6><a href="#results">Results</a></h6>
    <h6><a href="#discussion">Discussion</a></h6>
  </nav>
  </d-contents>
  -->

  <h2 id="introduction">Introduction</h2>

  <p> More general things </p>

  <p>
     In Maturana and Varela work <dt-cite key="VarelaThompsonEmbo"></dt-cite>, cognition is centered around how an agent "reacts" to the perturbation induced by its environment . More precisely, they introduce the notion of cognitive domain of a self-organizing system which are all the perturbations induced by the environment which do  not result in the destruction of the self-organizing system. Their notion of cognition is thus deeply linked with how a self-organizing creature will try to preserve its integrity in its environment.
  </p>

  <p>
      From their theories, studies has been made to apply those notion to examples of self-organizing systems. For example, the game of life and especially the glider has been studied under their paradigm <dt-cite key="PMID:24494612"></dt-cite> showing again the richness and complexity of such system. However, even if the glider in the game of life has shown to be a good toy model to explicit those theories with interesting interaction, they're also quite simple entity that are not very robust, with a lot of perturbation leading to destruction. (Also in those work, the environment wasn't well defined like walls food etc, but rather other structure.)
  </p>

  <p>
    In biology, We also find sensorimotor capabilities at the macro scale for example in swarm of  bacteria <dt-cite key="PhysRevE.101.012407"></dt-cite>  where a group of bacteria seem to avoid a wall of antibiotics. group decision making for obstacle avoidance
  </p>

  <p>
    Other studies, taking inspiration from biological regrowth in some animals, focused on the recovery from Deformation/ damage  <dt-cite key="horibe2021regenerating"></dt-cite> <dt-cite key="mordvintsev2020growing"></dt-cite>, applying Cellular automata to build and regenerate damaged parts.
  </p>
  <p>
    IN Lenia <dt-cite key="chan2020lenia"></dt-cite> <dt-cite key="chan2019lenia"></dt-cite> , we can see some sort of sensorimotor capabilities. However, even if there are interaction between some entity, there is no well define environment. The search for new creature in Lenia was first done manually testing parameters and mutating it or with simple evolutionary algorithm for moving creature for example. Other studies <dt-cite key="etcheverry2020hierarchically"></dt-cite>  <dt-cite key="reinke2020intrinsically"></dt-cite> focused on exploring as much as possible the space of creature in Lenia using intrinsically motivated explorer  . However this last techniques had a hard time finding moving creature.
  </p>

  <p>
    In cellular automata, what's interesting is that we have the same local update rule  applied to every cell (no cell has a special role ), yet it allows to have very complex self organizing structure. In this work, we'll show how to learn the Ca update rule leading to robustness and sensorimotor capabilities with walls. The creature we obtain, from the deformation induced by the walls on some part of it make new deicision at the macro level on where to go/how to react. What's even more interesting is that the computation made for the decision are all made in the creature itself, at the morphology level. (Each cell then from its neighboors know what it should do.)
  </p>

  <p>
    In this work, we
    no well define environment and creature obtained by luck and not very robust.
    swarm robotics ?
  </p>






  <dt-byline></dt-byline>
  <h2 id="system"> The system </h2>
  <img src="LeniaWall.svg" alt="scheme" class="l-screen-inset">


  <h4> Lenia </h4>
  <p>
     The cellular automaton we will study in this work is Lenia <dt-cite key="chan2020lenia"></dt-cite><dt-cite key="chan2019lenia"></dt-cite>. Lenia is a system of continous cellular automata where a wide variety of complex behavior has already been osberved, including what looks like sensorimotor-capabilities. In this work i will use the multi channel, multi kernel version of Lenia <dt-cite key="chan2020lenia"></dt-cite> but for simplicity we will only use 1 channel for the creature and other ones for the environment.
  </p>
  <p>
     A Lenia system like all CA starts from an initial pattern and iteratively update every pixel based on its neihgbours. The CA rule is given by the kernels and associated growth map which are both parametrized. So to find creatures we need to find both interesting CA rules and initialization. This is different from the game of life where the CA rule is fixed and initialization pattern are searched. Finding interesting rules from random exploration can be hard, especially in higher dimensions or when the number of kernels is big. This motivates our choice for gradient based method.
  </p>




  <h4> Walls </h4>
  <p>
  To implement walls in Lenia we added a walls channels with a kernel from the wall channel to the creature channel. This kernel have a huge negative growth where there are walls and no impact on other pixels where there are no walls (very localized kernel). This way we prevent any growth in the pixels where there are walls. This is  similar to  <dt-cite key="PhysRevE.101.012407"></dt-cite> where they put antibiotic zone as obstacle where the bacteria can't live. The creature can only sense the wall through the changes/deformations it implies on the creature, so the creature has to "touch" the wall to sense it. (And because of the cellular automaton nature of the creature the information  has to be transmitted to other cells.)
  </p>

  <p>
  Note that we used kernel for the walls so that the system stays under the Lenia paradigm using local kernels only  for the updates.
  </p>
  <p>
    In this study, the creature can't have any impact on the walls. This differs from other studies such as <dt-cite key="PMID:24494612"></dt-cite> in the game of life where the creature also perturb it's environment.
  </p>
  <p>
      Glider type of creature has been found in 1 channel lenia. However, they're not very robust to walls as shown here:
  </p>
  <div class="row l-body">
    <div class="column">
      <video id="robust" width="95%" autoplay loop muted="" class="videoShow">
                    <source src="orbium.mp4" type="video/mp4">
                  </video>
    </div>
    <div class="column">
      <video id="robust" width="95%"  autoplay loop muted="" class="videoShow">
                    <source src="orbiumWallb.mp4" type="video/mp4">
                  </video>
    </div>
  </div>


  <h4> Differentiable Lenia </h4>
  <p>
      Now that the environment is defined, we want to learn both the initialization and the CA rules leading to interesting behaviors. All parameters of the CA rule will be optimized, as well as the initialization which will be a square of fixed size.( each pixel will have its value optimized)
  </p>

  <p>
      To learn these parameters we chose to use gradient descent method. Thus we tried to make Lenia as Differentiable friendly as possible. To do so, the main shift is to use "free kernels", using kernels in the form of a sum of n overlapping gaussian bumps: $$x \rightarrow \sum_i^{n} b_i exp(-\frac{(x-rk_i)^2}{w_i}) $$ The parameters are then 3  n dimensional vectors: b for height of the bump, w for the size of the bump and rk for the center of the bump.
  </p>

  <img src="freeK.png" alt="schemeK" class='l-body' >
  <p>
    We did this shift because in the vanilla version of Lenia, the shape of the kernel was only given by a vector b of arbitrary size (but often max size 4). The number of bumps was given by the number of coefficient in b>0. However, the fact that the number of bumps depends on the number of coefficient > 0 prevents proper differentiation.
(if a coefficient is at 0 then it won't change with gradient descent as it doesn't play a role, and if a coefficient is >0 a gradient step can put it <0 which will make a strong unexpected change). We could have left the number of bumps to an arbitrary value like 3, and only optimizing the height such as they stay >0  but this would have been a strong limitation on the shape. The "free kernels", in addition to differentiation, allow more flexibility than the vanilla bumps but at the cost of more parameters.
  </p>
  <p>
  However even doing so, differentiating through Lenia can be difficult because we often have a big number of iterations and each iteration has it's result clipped between 0 and 1. We should thus limit ourselves to few iterations when training.
  </p>







  <h2 id="movingCrea">Can we learn Moving Creature in Lenia ? </h2>
  <img src="OptimStep.svg" alt="optimScheme" class='l-middle-outset' >
  <p>
    Before trying to find sensorimotor capabilities in our system a first step would be to find moving creatures like glider in the game of life. Note that moving creature in cellular automaton differ from other type of movement like muscle contraction or soft robot (article) by the fact that moving is growing at the front and dying at the back. This shoumd imply that creatures that move are more fragile because they  are in a fragile equilibrium between growth (to move forward) and dying (because otherwise we would have infinite growth).
   In this paper, we learn to develop morphology and motricity at the same time. The CA rule will both be applied to grow the creature from an initial state and be the "physic" that makes it move.
 </p>

 <p>
    Target image with MSE error seems effective to learn CA rule leading to certain pattern <dt-cite key="mordvintsev2020growing"></dt-cite>. And the fact that it's a very informative loss, thus helping with vanishing gradient problem made us choose this loss for our problem over other losses such as maximizing the coordinate of the center of mass . The first target shape we tried was a single disk. However after seeing  that robust creature obtained seemed to have a "core" and a shallow envelopp, we informally chose to move to two superposed disk, a large shallow one with a thick smaller one on top. The target shape has the formula:   \(0.1*(R<1)+0.8*(R<0.5)\). We chose on purpose to have the sum to be smaller than 1 because as we clip to 1 the pixels after each update it/s  better to have pixel below 1 than pixel saturated if you want to have gradients.
 </p>

 <p>
   However simply putting a target shape far from initialization and optimize towards it does not work most of the times. In fact,  it works only when the target is not too far from where the creature ended before optimization (so after the random initialization) . This comes from the fact that applying a lot of steps, each clipped, prevents gradient from flowing. The solution we propose to go further than this is curriculum learning.

 </p>




 <h3>IMGEP and Utility of curriculum</h3>

 <p>
   In fact, once we obtain a creature able to go a little further than the initialisation, we can push the target a little bit and learn to attain it. This time the new target needs to overlap where the creature is able to go  after the first optimisation. Then we just need to iterate this process.
 </p>

 <p>
   The effectiveness of curriculum with complex task has already been shown in <dt-cite key="DBLP:journals/corr/abs-1901-01753"></dt-cite> where they . And in complex self organizing systems in <dt-cite key="variengien2021selforganized"></dt-cite>

 </p>

 <p>
   One modular way we introduced it was using IMGEP <dt-cite key="Forestier2017IntrinsicallyMG"></dt-cite>  which has already been used as an explorative tool in Lenia to explore the morphological space <dt-cite key="etcheverry2020hierarchically"></dt-cite> <dt-cite key="reinke2020intrinsically"></dt-cite>.
 </p>
 <p>
   The general idea of IMGEP is to iteratively set new goals to achieve  and for each of these goals try to learn a policy that would suit this goal. THis way an IMGEP needs an interesting way to sample new goal for example based on intrinsic reward. It also needs a way to track the progress on this goal, and a way to optimize toward this goal. It also might use the knowledge acquired on other goals to learn new goals or attain them more quickly.

 </p>
 <p>
   In our case, the goal space will simply be a 2 dimensional vector representing the position of the center of mass of the creature at last timestep. The way we sample the goals depends on the task but to have a moving creature that goes far in the grid, we will randomly sample position in the grid biasing the sampling toward one edge of the grid. we use MSE error between the last state and our target shape centered at the target goal to try to achieve this goal. The way we reuse knowledge acquired is by intializing the parameters by the one that achieved the closest goal.
 </p>
<div class="l-middle-outset" style="position:relative">
 <img id="schemeIMGEP" src="IMGEP.svg" alt="IMGEPscheme" width="100%" usemap="#workmap">
 <div style="position:absolute; left:80%; top:79%; width:17%; height:9%; background-color: rgba(0, 0, 0, .25);z-index:5;" onmouseover="changeImgIMGEP('IMGEP1.svg')" onmouseout="changeImgIMGEP('IMGEP.svg')"></div>
 <div style="position:absolute; left:39%; top:85%; width:17%; height:11%; background-color: rgba(0, 0, 0, .25);z-index:5;" onmouseover="changeImgIMGEP('IMGEP2.svg')" onmouseout="changeImgIMGEP('IMGEP.svg')"></div>
 <div style="position:absolute; left:25%; top:11%; width:16%; height:13%; background-color: rgba(0, 0, 0, .25);z-index:5;" onmouseover="changeImgIMGEP('IMGEP3.svg')" onmouseout="changeImgIMGEP('IMGEP.svg')"></div>
 <div style="position:absolute; left:58%; top:36%; width:14%; height:13%; background-color: rgba(0, 0, 0, .25);z-index:5;" onmouseover="changeImgIMGEP('IMGEP4.svg')" onmouseout="changeImgIMGEP('IMGEP.svg')"></div>
 <!---
 <map name="workmap" style:"">
  <area shape="rect" coords="752,368,883,408" onmouseover="changeImgIMGEP('IMGEP1.svg')" onmouseout="changeImgIMGEP('IMGEP.svg')" >
  <area shape="rect" coords="372,400,507,443" onmouseover="changeImgIMGEP('IMGEP2.svg')" onmouseout="changeImgIMGEP('IMGEP.svg')" >
  <area shape="rect" coords="238,50,374,110"  onmouseover="changeImgIMGEP('IMGEP3.svg')" onmouseout="changeImgIMGEP('IMGEP.svg')" >
</map>--->
</div>



 <p  style="font-size: 14px;color:#A0A0A0;text-align:center;" class="l-middle-outset">
  Lenia Step (hover over gray area to show step by step)
 </p>



 <p>
   The overall method can be summarized as such:
 </p>

<!---<div style="display:block;background:rgba(0, 0, 0, 0.04);font-size:14px;line-height: 1.5;color:rgba(0, 0, 0, 0.6);border-left:-1px solid rgba(0, 0, 0, 0.05);padding: 0 0 0 24px"> --->
<dt-code block language="python" class='l-body'>
    <p>Initialize randomly the history (sampling random parameters)</p>
    <p>loop (number of Imgep step) </p>
    <p >   sample target position/goal</p>
    <p >   Select the policy that achieved the closest position/goal</p>
    <p>   loop (number of optimisation steps)</p>
    <p>       Run lenia
    <p>       Gradient descent toward the disk at target position</p>
    <p>   See what is the position(ie goal) achieved</p>
</dt-code>




 <h2 id="robustCrea"> Can we learn robust creatures with sensorimotor capabilities ?</h2>
 <img src="Merge.svg" alt="schemeLearn" width="100%" class="l-middle-outset" >

     <p  style="font-size: 13px;color:#A0A0A0;">
      Initialization is the yellow square  Green dashed line is at the same position in both.; <br>

     Left: reached goal/position library in green, target goal in red. THe policy selected is the one reaching the position in purple circle <br>

      Right:  Blue disks are the obstacles, red the target shape and green the creature at last timestep before optimisation .
     </p>





 <p>
  Now that we have an algorithm that is capable of learning moving creature in Lenia. the next step is to find a way to learn a creature that would resist and avoid obstacles in its environment, using the deformations the environment induces on it to sense. In this section, we'll try from scratch to learn a single CA rule and initialization that lead to building, moving and regenerating creature. So we will learn a single global rule for multiple functions contrary to  <dt-cite key="horibe2021regenerating"></dt-cite> which separates regenerating and building into two different CA.
 </p>

 <p>
  What we want to obtain is a creature that is able to generalize to different obstacles. To do so we will train the creatures using the method from previous section  but adding randomly generated obstacles. This way our gradient descent will be stochastic gradient descent with the stochasticity coming from the sampling of the obstacles. The learning process will thus encounter a lot of different configurations and may find general behavior. In practice, we will only put obstacles in half the lattice grid. This way, there will be half of the grid free from obstacle where we will first learn a creature that is able to move without any perturbation as in previous section and then as we push the target further and further the creature will start to encounter obstacles. And the deeper the target position is, the more it will encounter obstacles  and so the more it should be robust. In fact at the beginning you will just be a little perturbed by one obstacle and the target circle will optimize the creature to get past the obstacle and recover. (scheme) Then if you want the creature to go further it will have to encounter more obstacles and still be able to resist the second one even if the first one perturbed it. See appendix for more details on the obstacles.
 </p>
 <p>
  In the IMGEP, to take into account the fact that the position attained depends on the obstacle configuration, the reached goal will be an average of the position attained on different configurations of obstacles.
 </p>
<h3>Overcoming "bad initialization" problem </h3>

<img src="dependencies.svg" alt="schemeLearn" width="100%" class="l-body" >
<p  style="font-size: 13px;color:#A0A0A0;">
 The arrows show the dependencies between the creatures, the back of the arrow is the creature which initializes the optimization and the head of the arrow is the creature obtained after optimization. The arrows are only to show how much initialization and first optimisation steps mattter but dependencies is not used.
</p>

<p>
  <!---
  Note that the random initialization of the history using random paramaters can have a huge impact on the following steps. Because it will be the basis on which optimization will be made. We will select one randomly, and do the first optimization steps on top of it. And as it will lead to a creature that goes a little bit further, when we'll sample new goal we will most of the time select this creature as the basis for the new optimization. Which will lead to a creature going further which in consequence will also be sampled after. And so in most of the run, most of the creature will be based more or less closely on the initialization selected and also the first steps. However, if the initialization is "bad" or the first IMGEP steps, on which the nexts will be based, go in the "wrong" optimisation direction, optimization problems can arise.
  --->
  Note that the random initialization of the history using random paramaters and the first steps have a huge impact on the performance of the method. Because it will be the basis on which most of the next optimization will be made.In fact, we will select one random initialization, and do the first optimization step on top of it. And as it will lead to a creature that goes a little bit further, when we'll sample new goal we will most of the time select this creature as the basis for the new optimization. Which will lead to a creature going further which in consequence will also be sampled after. And so in most of the runs, most of the creatures will be based more or less closely on the random initialization selected and also the first steps. However, if the initialization is "bad" or the first IMGEP steps, on which the nexts will be based, go in the "wrong" optimisation direction, optimization problems can arise.
</p>

 <p>
  While training with this algorithm sometimes the optimisation could not get creature getting passed the obstacles, and would diverge to exploding or dying creature. This can be mitigated by adding random mutations before optimizing that could lead to better optimization spots by luck. It may unstuck the situation however the creature after mutation are often not that good and most of the time far from the previously achieved goal (because mutation often make "suboptimal" creature that may be slower than the one before mutation) which prevent learning. So mutation can help unstuck situation but also slows the training. This is why we apply less optimization steps for the mutated one, see appendix for more details.
 </p>

 <p>
   This does not solve the problem 100% of the time and that's why we also apply initialization selection. We run the first steps of the methode (random initialization and optimization), until we find an initialization which gives a good loss for the 3 first  deterministic target (placed before the obstacles). Because the first steps will be the basis of most of the creatures and so if it struggle to make a moving creature, it will be hard for it to learn the senorimotor capabilities on top .This way we only keep the initializations and first steps that learned quickly and seemed to have room for improvement.
 </p>


<h2 id="results"> Results </h2>

<div class="row l-body">
<div class="column">
  <video id="robust" width="95%" controls="" loop muted="" class="videoShow">
                <source src="robust.mp4" type="video/mp4">
              </video>
</div>
<div class="column">
  <video id="robust" width="95%" controls="" loop muted="" class="videoShow">
                <source src="robust2.mp4" type="video/mp4">
              </video>
</div>
</div>
<div style="position:fixed;bottom:0;left :-200px;">
  <input type="range" min="0.1" max="3"  step="0.1" value="1" class="slider" id="rangeSpeed" >
  <p> Speed of video: <span id="valueSpeed"></span></p>
</div>
<p>
(each IMGEP step is only 100 gradient steps and the lenia rollout is only 50 timesteps and obstacles are only simple circles.)
</p>
<h3> How well do the creatures obtained generalize ? </h3>

<h4> are the creature long term stable ?</h4>
<p>
Even if we can not know if the creature is indefinitively stable, we can test for reasonable number of timesteps. The result is that the creature obtained with IMGEP with obstacles seems stable for 2000 timesteps while it has only been trained to be stable for 50 timesteps. This might be because as it learned to be robust to deformation it has learned a strong preservation of the structure to prevent any explosion or dying when perturbed a little bit. And so when there is no perturbation this layer of "security" strongly preserves the structure. However, Training a creature only for movement(without obstacles  so no perturbation during training) sometimes led to non long term stable creatures. This is similar to what has been observed in <dt-cite key="mordvintsev2020growing"></dt-cite> where training to grow a creature from the same initialization (a pixel) led to pattern that were not long term stable. But adding incomplete/perturbed patterns as initialization to learn to recover from them led to long term stability. (by making the target shape a stronger attractor)
</p>
<h4> Are the creatures robust to new obstacles ?</h4>
<p>
  The resulting creatures are very robust to walls perturbations and able to navigate in difficult environment. The resulting creature seems able to recover from perturbation induced by various shape of wall including vertical walls.(see interactive demo) One very surprising emerging behavior is that the creature is sometimes able to come out of dead end showing how well this technique generalizes. There are still some failure cases, with creature obtained that can get unstable after some perturbation, but the creatures are most of the time robust to a lot of different obstacles. The generalization is due to the large diversity of obstacles encountered by the creature during the learning because 8 circle randomly placed can lead to a very diverse set of obstacles. Moreover as it learns to go further, the creature have to learn to collide with several obstacles one after the other and so be able to recover fast but also still be able to resist/sense a second obstacle while not having fully recover.
</p>

<h4> Are the creatures robust to Moving obstacles ?</h4>
<video id="model-editing-level-1-video-1"  autoplay loop muted="" class="videoShow l-middle side">
              <source src="harderEnv.mp4" type="video/mp4">
            </video>

  <p>
  We can make an harder out of distribution environment by adding movement to the obstacles. For example we can do bullet like environment where the tiny wall disks are shifted of few pixels at every step. The creature seems quite resilient to this kind of perturbation even if we can see that a well placed perturbation can kill the creature. However, this kind of environment differs a lot of what the creature has been trained on and therefore shows how much the creature learned to quickly recover from perturbations, even unseen ones.
 </p>


  <h4> Are the creature robust to Asynchronous update with noise ? </h4>
  <video id="model-editing-level-1-video-1"  autoplay loop muted="" class="videoShow l-middle side">
                <source src="asynchro.mp4" type="video/mp4">
              </video>
    <p>
      As done in <dt-cite key="mordvintsev2020growing"></dt-cite>, we can relax the assumption of synchronous update (which assumes a global clock) by adding stochastic update. By applying a mutation mask on each cell which is on in average 50% of the time we get partial asynhcronous updates. The creature we obtained with the previous training with synchronous updates seem to behave "normally" with stochastic updates. The creature is slowed a little bit but this is what we can expect as each cell is updated in average 50% of the time.
     </p>

<h4> Are the creature robust to change of scale ? </h4>
<!---
<video id="model-editing-level-1-video-1"  autoplay loop muted="" class="videoShow l-gutter">
              <source src="small.mp4" type="video/mp4">
            </video>
--->
<video id="model-editing-level-1-video-1"  autoplay loop muted="" class="videoShow l-middle side">
              <source src="smallerDie.mp4" type="video/mp4">
            </video>
      <p class="l-gutter"  style="font-size: 12px;color:#A0A0A0;">
        The grid is the same size as above to give you an idea of the scale change( kernel radius *0.4)
      </p>
<p> We can change the scale of the creature by changing the radius of the kernels as well as the size of the initialization square. This way we can make much smaller creature that therefore have less pixels to do the computation. This scale reduction has a limit but we can get pretty small creature. The creature stil seem to be quite robust and be able to sense and react to their environment while having less space to compute. The creature are even able to reproduce, however they seem to be less robust than the bigger one as we can see some dying from collision. We can also do it the other way and have much bigger creature that therefore have more space to compute. </p>


  <h3> Side effects</h3>

  <h4>Multi creature setting</h4>
   <p>
    By adding more initialization square in the grid, we can add several creature with the same update rule. As pointed out in <dt-cite key="PMID:24494612"></dt-cite>, other entity are also part of the environment for the creature and can give rise to nice interactions. Maturana and Varela even refer to this kind of interaction as communication.
   </p>

  <h4>Individuality</h4>
   <video id="robust" width="95%"  autoplay controls="" loop muted="" class="l-body videoShow">
                 <source src="demo.mp4" type="video/mp4">
               </video>
   <p>
     The creature obtained shows strong individuality preservation. In fact, creatures goes in non destructive interactions most of the times without merging. As said before, we can tune the weight of the kernels (especially the limiting growth one) to make the merge of two creature harder. By increasing those limiting growth kernels, the repeal of two entities get stronger and they will simply change direction.
   </p>
   <h4>Attraction</h4>
   <video id="robust" width="95%"  autoplay controls="" loop muted="" class="l-body videoShow">
                 <source src="stick.mp4" type="video/mp4">
               </video>

   <video id="robust" width="95%"  autoplay  loop muted="" class="l-gutter videoShow">
                 <source src="stickFar.mp4" type="video/mp4">
               </video>
     <p class="l-gutter" style="font-size: 13px;color:#A0A0A0;  ">
       If they are too far from each other no attraction.
     </p>

   <p>
     One other type of interaction between two creature of the same species(governed by the same update rule/physic) is creature getting stuck together. The two creatures seem to attract each other a little bit when they are close enough leading to the two creature stuck together going in the same direction. When they encounter an obstacle and separate briefly, their attraction reassemble them together. Even when they're stuck together, from a human point of view seeing this system, we ce can still see 2 distinct creatures. This type of behavior is  studied in the game of life in <dt-cite key="PMID:24494612"></dt-cite>  with the notion of consensual domain.
   </p>

  <h4>Reproduction</h4>
  <video id="robust" width="95%"  autoplay  controls="" loop muted="" class="l-body videoShow">
                <source src="repro.mp4" type="video/mp4">
              </video>
   <p>
     Another interesting interaction we observed during colision was "reproduction". In fact for some collision, we could observe the birth of a 3rd entity. This kind of interaction seemed to happen when one of the two entity colliding was in a certain "mode" like when it just hit a wall. Our intuition is that when it hits a wall, it has to have a growth response in order to recover. And during this growth response if we add some perturbation of another entity it might separate this growth from the entity and then this separated mass from strong self-organization grows into a complete individual.
   </p>

<h3> Study of the creature </h3>
 <p>
   What's interesting in such system is that the computation of decision is done at the macro (group) level, showing how a group of simple identical entities through local interactions can make "decision", sense at the macro scale. Seeing these creature it's even hard to believe that they are in fact made of tiny part all behaving under the same rules.
 </p>
 <video id="robust" width="95%"  autoplay  controls="" loop muted="" class="l-body videoShow">
               <source src="damageHand.mp4" type="video/mp4">
             </video>
 <p>
   In fact in order to navigate, first it need to sense the wall through a deformation of itself. Then after this deformation it has to make a collective "decision" on where to grow next and then move and regrow it's shape. We can even do the deformation ourselves by suppressing a part of the creature.
 </p>
 <p>
   After visualizing the kernels and doing informal ablation studies it seems that the creature we obtain have "limiting growth" kernel that tries to prevent the creature from growing too much beyond its boundaries and also growth kernel. Those two type of kernel are in equilibrium but We can play with the weight of each kernel  a little bit without destroying this equilibrium. For example the main utility we found of this is that "limiting growth" kernels can be given more importance to enforce the individuality of the creature and prevent several creature colliding from merging (see next section) because it gives stronger boundaries. However putting too much weight on those limiting kernels can lead to creature dying from too much damage as you inhibit growth.
 </p>

 <p>
   Surprisingly some creature looked a lot like (in term of morphology) creature from <dt-cite key="chan2019lenia"></dt-cite> which were obtained by evolutionary algorithm or by hand made mutations but seem to be far more robust.
 </p>



<h3>Different target shape</h3>

 <p>
   To try to have more diversity in the morphology of the creature we tried to change the target shape. In fact as the creature is optimized to fit this shape at the last timestep we can expect that changing this shape may lead to other morphologies.
 </p>

 <p>
   However we tried with half circle, star and sharp star without success. For all of these shape we still obtained roundish morphologies. This may be due to the kernel shape which bias the shape of the creature. However as shown in the appendix, we can optimize the growth toward a complicated gecco shape. The failure of these optimisation may be due to the difficulty added by the fact that we want a moving creature.Thus When we optimize the MSE loss, before trying to make this complicated shape the optimization first learns to get the creature to where it should be, and trying to grow it into this star shape may not be well aligned with this.
 </p>

<video id="robust" width="95%"  autoplay  controls="" loop muted="" class="l-body videoShow">
              <source src="2circlewall.mp4" type="video/mp4">
            </video>
 <p>
   We still tried to have roundish shape different from a single disk. For example we put as our target 2 disk target(defined \ref{}) close, overlapping a little bit. And the creature it produced was a creature seemingly composed of two roundish creature stuck together. But the force of their attraction is quite big as even when one of the creature collide an obstacle, they keep being stuck. And even when they seem to separate from a collision with an obstacle, they each independently follow the obstacle until they merge again.(However we can see at the end of the clip that they start to explode at the end) This type of behavior might be hard to get from random exploration as small mutation on the CA rule easily break this attraction leading to 2 separate creature going their own way from initialization or even worse lead to repealing creature.
 </p>

<h3>Still failure cases</h3>

<p>
  One is very robust but with different configuration it's possible to kill or explode others creature. However they were only trained for 50 timesteps (2seconds in the clips above) and witth always the same 8 type of obstacle (even if their position induced diversity). Further training of the parameters for more robustness should be achievable.

</p>
<p>

  Video Of failure
</p>

<h2> Related works </h2>

<h4>Classic CA cognition </h4>
<h4>Neural CA</h4>
<h4>Soft robots</h4>
<h4>Exploration</h4>

 <h2 id="discussion"> Discussion </h2>

 <p>
    Surprising to see that the creature is able to do all the computation required for changing direction in itself.
 </p>

 <p>
   radius is quite big while <dt-cite key="mordvintsev2020growing"></dt-cite> Moore neighbourhood size 3. (but no hidden channel)
   Even if this, this work still provides interesting idea on how to learn parameters in complex systems that can be very sensitive, especially how to deal with certain problems such that vanishing gradient, bad initialization.

 </p>

 <p>
   Improve the diversity and so the diversity in selection could help with the bad initialization problem.
 </p>

 <p>
   food?
   discussion difficulty coming from other agents becoming stronger competition in evolution/\cite{baker2020emergent}). Future work might use these creature as basis for species mutate them and make them compete for food.
 </p>






</dt-article>

<dt-appendix>
  <video id="kernels" width=85% controls="" muted="" class="videoShow" >
                <source src="kernels.mp4" type="video/mp4">
              </video>
  <video id="kernels" controls="" muted="" class="videoShow" >
                <source src="slalom.mp4" type="video/mp4">
              </video>

  <h3> Breeding and mutation </h3>
  <h3> Food </h3>
  <video id="model-editing-level-1-video-1" controls="" muted="" class="videoShow">
                <source src="demoFoodc.mp4" type="video/mp4">
              </video>
  <h3> Mutation by hand </h3>
</dt-appendix>

<script type="text/bibliography">
  @article{DBLP:journals/corr/abs-1901-01753,
  author    = {Rui Wang and
               Joel Lehman and
               Jeff Clune and
               Kenneth O. Stanley},
  title     = {Paired Open-Ended Trailblazer {(POET):} Endlessly Generating Increasingly
               Complex and Diverse Learning Environments and Their Solutions},
  journal   = {CoRR},
  volume    = {abs/1901.01753},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.01753},
  archivePrefix = {arXiv},
  eprint    = {1901.01753},
  timestamp = {Tue, 29 Sep 2020 10:47:58 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-01753.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
  }

  @article{autopoiesisBeer2004,
    author    = {Randall D. Beer},
    title     = {Autopoiesis and Cognition in the Game of Life.},
    journal   = {Artif Life},
    volume    = {10(3)},
    year      = {2004},
    url       = { https://doi.org/10.1162/1064546041255539},

  }


  @misc{chan2020lenia,
        title={Lenia and Expanded Universe},
        author={Bert Wang-Chak Chan},
        year={2020},
        eprint={2005.03742},
        archivePrefix={arXiv},
        primaryClass={nlin.CG}
  }

  @misc{chan2019lenia,
        title={Lenia - Biology of Artificial Life},
        author={Bert Wang-Chak Chan},
        year={2019},
        eprint={1812.05433},
        archivePrefix={arXiv},
        primaryClass={nlin.CG}
  }

  @article{mordvintsev2020growing,
    author = {Mordvintsev, Alexander and Randazzo, Ettore and Niklasson, Eyvind and Levin, Michael},
    title = {Growing Neural Cellular Automata},
    journal = {Distill},
    year = {2020},
    note = {https://distill.pub/2020/growing-ca},
    doi = {10.23915/distill.00023}
  }

  @misc{etcheverry2020hierarchically,
        title={Hierarchically Organized Latent Modules for Exploratory Search in Morphogenetic Systems},
        author={Mayalen Etcheverry and Clement Moulin-Frier and Pierre-Yves Oudeyer},
        year={2020},
        eprint={2007.01195},
        archivePrefix={arXiv},
        primaryClass={cs.LG}
  }

  @misc{reinke2020intrinsically,
        title={Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing Systems},
        author={Chris Reinke and Mayalen Etcheverry and Pierre-Yves Oudeyer},
        year={2020},
        eprint={1908.06663},
        archivePrefix={arXiv},
        primaryClass={cs.LG}
  }

  @misc{horibe2021regenerating,
        title={Regenerating Soft Robots through Neural Cellular Automata},
        author={Kazuya Horibe and Kathryn Walker and Sebastian Risi},
        year={2021},
        eprint={2102.02579},
        archivePrefix={arXiv},
        primaryClass={cs.NE}
  }

  @misc{sudhakaran2021growing,
        title={Growing 3D Artefacts and Functional Machines with Neural Cellular Automata},
        author={Shyam Sudhakaran and Djordje Grbic and Siyan Li and Adam Katona and Elias Najarro and Claire Glanois and Sebastian Risi},
        year={2021},
        eprint={2103.08737},
        archivePrefix={arXiv},
        primaryClass={cs.LG}
  }

  @misc{baker2020emergent,
        title={Emergent Tool Use From Multi-Agent Autocurricula},
        author={Bowen Baker and Ingmar Kanitscheider and Todor Markov and Yi Wu and Glenn Powell and Bob McGrew and Igor Mordatch},
        year={2020},
        eprint={1909.07528},
        archivePrefix={arXiv},
        primaryClass={cs.LG}
  }

  @article{PhysRevE.101.012407,
    title = {Active modulation of surfactant-driven flow instabilities by swarming bacteria},
    author = {Kotian, Harshitha S. and Abdulla, Amith Z. and Hithysini, K. N. and Harkar, Shalini and Joge, Shubham and Mishra, Ayushi and Singh, Varsha and Varma, Manoj M.},
    journal = {Phys. Rev. E},
    volume = {101},
    issue = {1},
    pages = {012407},
    numpages = {10},
    year = {2020},
    month = {Jan},
    publisher = {American Physical Society},
    doi = {10.1103/PhysRevE.101.012407},
    url = {https://link.aps.org/doi/10.1103/PhysRevE.101.012407}
  }



  @misc{barnett2021dynamical,
        title={Dynamical independence: discovering emergent macroscopic processes in complex dynamical systems},
        author={Lionel Barnett and Anil K. Seth},
        year={2021},
        eprint={2106.06511},
        archivePrefix={arXiv},
        primaryClass={nlin.AO}
  }
  @misc{krakauer2020information,
        title={The Information Theory of Individuality},
        author={Krakauer, D., Bertschinger, N., Olbrich, E. et al.},
        year={2020},
        journal = {Theory Biosci},
        volume = {139,},
        pages = {209–223},

  }

  @article{Beer2015CharacterizingAI,
    title={Characterizing Autopoiesis in the Game of Life},
    author={R. Beer},
    journal={Artificial Life},
    year={2015},
    volume={21},
    pages={1-19}
  }

  @article {PMID:24494612,
  	Title = {The cognitive domain of a glider in the game of life},
  	Author = {Beer, Randall D},
  	DOI = {10.1162/artl_a_00125},
  	Number = {2},
  	Volume = {20},
  	Year = {2014},
  	Journal = {Artificial life},
  	ISSN = {1064-5462},
  	Pages = {183—206},
  	Abstract = {This article examines in some technical detail the application of Maturana and Varela s biology of cognition to a simple concrete model: a glider in the game of Life cellular automaton. By adopting an autopoietic perspective on a glider, the set of possible perturbations to it can be divided into destructive and nondestructive subsets. From a glider s reaction to each nondestructive perturbation, its cognitive domain is then mapped. In addition, the structure of a glider s possible knowledge of its immediate environment, and the way in which that knowledge is grounded in its constitution, are fully described. The notion of structural coupling is then explored by characterizing the paths of mutual perturbation that a glider and its environment can undergo. Finally, a simple example of a communicative interaction between two gliders is given. The article concludes with a discussion of the potential implications of this analysis for the enactive approach to cognition.},
  	URL = {https://doi.org/10.1162/ARTL_a_00125},
  }

  @article{Forestier2017IntrinsicallyMG,
    title={Intrinsically Motivated Goal Exploration Processes with Automatic Curriculum Learning},
    author={Sebastien Forestier and Yoan Mollard and Pierre-Yves Oudeyer},
    journal={ArXiv},
    year={2017},
    volume={abs/1708.02190}
  }
  @book{VarelaThompsonEmbo,
    title={The embodied mind.},
    author={Varela ,F. J. and Thompson, E., and Rosch, E.},
    year={1991}

  }

  @misc{variengien2021selforganized,
      title={Towards self-organized control: Using neural cellular automata to robustly control a cart-pole agent},
      author={Alexandre Variengien and Stefano Nichele and Tom Glover and Sidney Pontes-Filho},
      year={2021},
      eprint={2106.15240},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}
</script>
<script type="text/javascript">
  "use strict";
  var sliderSpeed = document.getElementById("rangeSpeed");
  var outputSpeed = document.getElementById("valueSpeed");
  var videos=document.getElementsByClassName("videoShow");
  outputSpeed.innerHTML = sliderSpeed.value; // Display the default slider value

  // Update the current slider value (each time you drag the slider handle)
  sliderSpeed.oninput = function() {
  outputSpeed.innerHTML = this.value;
  for (var i = 0; i < videos.length; i++) {
  	videos[i].playbackRate = this.value;
  }}
  function changeImgIMGEP(img)
        {
            var schemeIMGEP=document.getElementById("schemeIMGEP");
            schemeIMGEP.src=img;
        }


</script>
<style>
button {
display: inline-block;
background-color: #7b38d8;
border-radius: 10px;
border: 4px double #cccccc;
color: #eeeeee;
text-align: center;
font-size: 15px;
padding: 10px;
width: 80px;
-webkit-transition: all 0.5s;
-moz-transition: all 0.5s;
-o-transition: all 0.5s;
transition: all 0.5s;
cursor: pointer;
margin: 5px;
}
button:hover {
background-color: lightgreen;
}

.radio-toolbar input[type="radio"] {
  opacity: 0;
  position: fixed;
  width: 0;
}

.radio-toolbar label {
    display: inline-block;
    background-color: #cbc;
    border-radius: 10px;
    border: 4px double #cccccc;
    color: #eeeeee;
    text-align: center;
    font-size: 15px;
    padding: 10px;
    width: 80px;
    -webkit-transition: all 0.5s;
    -moz-transition: all 0.5s;
    -o-transition: all 0.5s;
    transition: all 0.5s;
    cursor: pointer;
    margin: 5px;
}

.radio-toolbar input[type="radio"]:checked + label {
    background-color:green;
    border-color: #4c4;
}

.radio-toolbar input[type="radio"]:focus + label {
    border: 2px dashed #444;
}

.radio-toolbar label:hover {
  background-color: lightgreen;
}
</style>
